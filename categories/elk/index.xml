<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ELK on fyzn12</title>
    <link>https://fyzn12.github.io/categories/elk/</link>
    <description>Recent content in ELK on fyzn12</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 28 Jul 2021 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://fyzn12.github.io/categories/elk/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>k8s日志采集</title>
      <link>https://fyzn12.github.io/post/elk/%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86/%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86/</link>
      <pubDate>Wed, 28 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fyzn12.github.io/post/elk/%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86/%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86/</guid>
      <description>k8s日志采集架构选型  1，Node方式：每台节点采用DaemonSet部署agent：
原理：每台节点采用DaemonSet部署一个采集日志的agent，从/var/log/containers/目录采集所有容器的日志，而容器中的日志需要遵循docker的日志规范，把日志打入pid为1的主程序的stdout/stderr，这样k8s会自动在/var/log/containers/目录生成对应容器的日志。
优点：部署维护简单，且能收集所有容器的日志
缺点：需要应用程序日志支持stdout/stderr输出，如果每个节点的日志规模过多，单个采集日志的agent可能成为瓶颈，不太灵活。
2，pod的SideCar方式：
原理：每个pod通过SideCar方式部署一个采集日志的agent
优点：每个pod可单独配置agent，灵活性高
缺点：每个pod都需要一个SideCar比较麻烦
3，应用程序直接推送日志到日志存储：
原理：部署在pod的应用程序支持把日志直接推送到日志存储程序
优点：不用维护日志采集程序，运维简单
缺点：开发成本较高。
 三种日志采集模型比较    原生方式  DaemonSet方式  Sidecar方式    采集日志类型 标准输出 标准输出+部分文件  文件   部署运维 低，原生支持 一般，需维护DaemonSet 较高，每个需要采集日志的POD都需要部署sidecar容器   日志分类存储 无法实现 一般，可通过容器/路径等映射 每个POD可单独配置，灵活性高   多租户隔离 弱 一般，只能通过配置间隔离  强，通过容器进行隔离，可单独分配资源    支持集群规模 本地存储无限制，若使用syslog、fluentd会有单点限制  中小型规模，业务数最多支持百级别  无限制   资源占用  低，docker engine提供 较低，每个节点运行一个容器  较高，每个POD运行一个容器    查询便捷性 低  较高，可进行自定义的查询、统计 高，可根据业务特点进行定制   可定制性 低  低 高，每个POD单独配置   适用场景  测试、POC等非生产场景  功能单一型的集群 大型、混合型、PAAS型集群    容器内日志  和主机采集（daemonset）方式相比，容器内日志的采集方案一般使用 sidecar，好处是：</description>
    </item>
    
    <item>
      <title>ubuntu搭建单机版k8s</title>
      <link>https://fyzn12.github.io/post/k8s/ubuntu%E5%AE%89%E8%A3%85%E5%8D%95%E6%9C%BA%E7%89%88k8s/</link>
      <pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fyzn12.github.io/post/k8s/ubuntu%E5%AE%89%E8%A3%85%E5%8D%95%E6%9C%BA%E7%89%88k8s/</guid>
      <description>ubuntu18搭建单机版k8s  环境配置 1、 添加kubernetes的源
 echo &amp;#34;deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main&amp;#34; | sudo tee -a /etc/apt/sources.list.d/kubernetes.list 或者直接vim /etc/apt/sources.list 在后面添加deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main  2、 为源申请key
执行 apt-get update 这一步一般执行都会报错 因为不同版本的keys不同，执行之后会报如下错误
 查看到这个错误之后 执行sudo gpg &amp;ndash;keyserver keyserver.ubuntu.com &amp;ndash;recv-keys 后面是错误提示的keys 再执行 sudo gpg &amp;ndash;export &amp;ndash;armor 上面相同的keys | sudo apt-key add -
注意 --在markdown 编译后会变成一条横杠，其实这里是两条横杠  3、更新源
sudo apt-get update
4、关闭虚拟内存
sudo swapoff -a #暂时关闭 nano /etc/fstab #永久关闭，注释掉swap那一行，推荐永久关闭
5、执行安装 (sudo视操作者情况决定是否加)apt-get install kubelet kubeadm kubectl kubernetes-cni</description>
    </item>
    
    <item>
      <title>FileBeat</title>
      <link>https://fyzn12.github.io/post/elk/filebeat/</link>
      <pubDate>Fri, 18 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fyzn12.github.io/post/elk/filebeat/</guid>
      <description>一、 filebeat简单理解 1.1、filebeat和beats的关系  首先filebeat是Beats中的一员。 Beats在是一个轻量级日志采集器，其实Beats家族有6个成员，早期的ELK架构中使用Logstash收集、解析日志，但是Logstash对内存、cpu、io等资源消耗比较高。相比Logstash，Beats所占系统的CPU和内存几乎可以忽略不计。 目前Beats包含六种工具：
 Packetbeat：网络数据（收集网络流量数据） Metricbeat：指标（收集系统、进程和文件系统级别的CPU和内存使用情况等数据） Filebeat：日志文件（收集文件数据） Winlogbeat：windows事件日志（收集Windows事件日志数据） Auditbeat：审计数据（收集审计日志） Heartbeat：运行时间监控（收集系统运行时的数据） 1.2、filebeat是什么  　Filebeat是用于转发和集中日志数据的轻量级传送工具。Filebeat监视您指定的日志文件或位置，收集日志事件，并将它们转发到Elasticsearch或 Logstash进行索引。
　Filebeat的工作方式如下：启动Filebeat时，它将启动一个或多个输入，这些输入将在为日志数据指定的位置中查找。对于Filebeat所找到的每个日志，Filebeat都会启动收集器。每个收集器都读取单个日志以获取新内容，并将新日志数据发送到libbeat，libbeat将聚集事件，并将聚集的数据发送到为Filebeat配置的输出。
 1.3、filebeat和logstash的关系  　因为logstash是jvm跑的，资源消耗比较大，所以后来作者又用golang写了一个功能较少但是资源消耗也小的轻量级的logstash-forwarder。不过作者只是一个人，加入http://elastic.co公司以后，因为es公司本身还收购了另一个开源项目packetbeat，而这个项目专门就是用golang的，有整个团队，所以es公司干脆把logstash-forwarder的开发工作也合并到同一个golang团队来搞，于是新的项目就叫filebeat了。
 二、filebeat原理是什么 2.1、filebeat的构成  　filebeat结构：由两个组件构成，分别是inputs（输入）和harvesters（收集器），这些组件一起工作来跟踪文件并将事件数据发送到您指定的输出，harvester负责读取单个文件的内容。harvester逐行读取每个文件，并将内容发送到输出。为每个文件启动一个harvester。harvester负责打开和关闭文件，这意味着文件描述符在harvester运行时保持打开状态。如果在收集文件时删除或重命名文件，Filebeat将继续读取该文件。这样做的副作用是，磁盘上的空间一直保留到harvester关闭。默认情况下，Filebeat保持文件打开，直到达到close_inactive
关闭harvester可以会产生的结果：
 文件处理程序关闭，如果harvester仍在读取文件时被删除，则释放底层资源。 只有在scan_frequency结束之后，才会再次启动文件的收集。 如果该文件在harvester关闭时被移动或删除，该文件的收集将不会继续  　一个input负责管理harvesters和寻找所有来源读取。如果input类型是log，则input将查找驱动器上与定义的路径匹配的所有文件，并为每个文件启动一个harvester。每个input在它自己的Go进程中运行，Filebeat当前支持多种输入类型。每个输入类型可以定义多次。日志输入检查每个文件，以查看是否需要启动harvester、是否已经在运行harvester或是否可以忽略该文件
 2.2、filebeat如何保存文件的状态  Filebeat保留每个文件的状态，并经常将状态刷新到磁盘中的注册表文件中。该状态用于记住harvester读取的最后一个偏移量，并确保发送所有日志行。如果无法访问输出（如Elasticsearch或Logstash），Filebeat将跟踪最后发送的行，并在输出再次可用时继续读取文件。当Filebeat运行时，每个输入的状态信息也保存在内存中。当Filebeat重新启动时，来自注册表文件的数据用于重建状态，Filebeat在最后一个已知位置继续每个harvester。对于每个输入，Filebeat都会保留它找到的每个文件的状态。由于文件可以重命名或移动，文件名和路径不足以标识文件。对于每个文件，Filebeat存储唯一的标识符，以检测文件是否以前被捕获。
2.3、filebeat何如保证至少一次数据消费 　Filebeat保证事件将至少传递到配置的输出一次，并且不会丢失数据。是因为它将每个事件的传递状态存储在注册表文件中。在已定义的输出被阻止且未确认所有事件的情况下，Filebeat将继续尝试发送事件，直到输出确认已接收到事件为止。如果Filebeat在发送事件的过程中关闭，它不会等待输出确认所有事件后再关闭。当Filebeat重新启动时，将再次将Filebeat关闭前未确认的所有事件发送到输出。这样可以确保每个事件至少发送一次，但最终可能会有重复的事件发送到输出。通过设置shutdown_timeout选项，可以将Filebeat配置为在关机前等待特定时间。
 本文来源于： FileBeat</description>
    </item>
    
  </channel>
</rss>